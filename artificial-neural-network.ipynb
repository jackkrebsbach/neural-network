{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: Drone Classification\n",
    "##### Eric Leu, Josiah Brett, Jackson Krebsbach, Blake Harlow\n",
    "##### May 2020\n",
    "\n",
    "In this worksheet, we create an algorithm for training a neural network. We will then use it for classifying drone imagery and compare it to results obtained from package random forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First, we import the data that is in this same directory. These <code>.csv</code> files already contain the targets in the first column. The training data is seperate from the validation data, so we import the training and validation data as seperate dataframes. We then print the first five entries of the training dataframe in order to confirm that it was imported as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n",
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "# Create a data frame\n",
    "TrainDataframe = pd.read_csv('./train.csv')\n",
    "print(TrainDataframe.shape)\n",
    "TestDataframe = pd.read_csv('./val.csv')\n",
    "# Print the shapes\n",
    "print(TestDataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>NIR</th>\n",
       "      <th>Thermal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031719</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058563</td>\n",
       "      <td>0.102297</td>\n",
       "      <td>0.041034</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.957622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.089930</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.082407</td>\n",
       "      <td>0.028196</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059913</td>\n",
       "      <td>0.103095</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.957978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class      Blue     Green       Red   RedEdge       NIR   Thermal\n",
       "0    0.0  0.031719  0.076708  0.024127  0.005650  0.000000  0.958818\n",
       "1    0.0  0.058563  0.102297  0.041034  0.017704  0.001276  0.957622\n",
       "2    0.0  0.050540  0.089930  0.040690  0.013121  0.000000  0.958204\n",
       "3    0.0  0.044991  0.082407  0.028196  0.008350  0.000000  0.957364\n",
       "4    0.0  0.059913  0.103095  0.053527  0.025488  0.003190  0.957978"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDataframe[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first column contains the targets. Thus, we next assign the first column to be the targets and the remaining columns to be the parameters of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6) (500, 6)\n"
     ]
    }
   ],
   "source": [
    "TrainData = np.array(TrainDataframe.loc[:,'Blue':])\n",
    "TestData = np.array(TestDataframe.loc[:,'Blue':])\n",
    "print(TrainData.shape,TestData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "TrainVal = np.array(TrainDataframe.loc[:,'Class'])\n",
    "TestVal = np.array(TestDataframe.loc[:,'Class'])\n",
    "print(TrainVal.shape,TestVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have the data in four different numpy arrays. The training data is in <code>TrainData</code> and has targets in <code>TrainVal</code> and the testing data is in <code>TestData</code> and has targets in <code>TestVal</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "In order to begin coding the algorithm for the neural network, we first define some initial functions that will be used. First, we define the activation functions that we will use, the relu function and the softmax function. The former will be used as the activation function of the hidden layer and the later will be used as an activation function for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation function relu for forward propagation. \n",
    "#This includes both relu (type = 0) and\n",
    "#its unit step function derivative (type = 1).\n",
    "def relu(x,type):\n",
    "    #Perform regular relu\n",
    "    if(type==0):\n",
    "        #Loop over columns\n",
    "        for j in range(x.shape[1]):\n",
    "            #Loop over rows\n",
    "            for i in range(x.shape[0]):\n",
    "                if x[i,j] < 0:\n",
    "                    x[i,j] = 0\n",
    "    #Perform relu derivative\n",
    "    elif(type==1):\n",
    "        #Loop over columns\n",
    "        for j in range(x.shape[1]):\n",
    "            #Loop over rows\n",
    "            for i in range(x.shape[0]):\n",
    "                if x[i,j] < 0:\n",
    "                    x[i,j] = 0\n",
    "                else:\n",
    "                    x[i,j] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation function softmax for forward propagation. \n",
    "#The regular softmax function overflows whenever any input data is large due to the .exp() function.\n",
    "#I've modified it to shift the input vector to ensure calculations are stable.\n",
    "def softmax(x):\n",
    "    z = x-np.max(x,axis=1).reshape(x.shape[0],1)\n",
    "    return np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we code the algorithm that trains the neural network weights and biases. This function takes the training data along with its targets, along with a variety of hyperparamters. <code>numer_hiddennodes</code> gives the number of nodes in the hidden layer, <code>number_outputnodes</code> gives the number of nodes at the ouput layer, <code>learningrate</code> contributes to the step size, and <code>epochs</code> gives the number of iterations that the model completes. Notice that <code>number_outputnodes</code> must be equal to the expected dimesion of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network for our classification problem.\n",
    "#It is fit through a set of training data then outputs the final optimized weights and bias for training and validation.\n",
    "def NeuralNetwork(TrainData,TrainVal,number_hiddennodes,number_outputnodes,learningrate = 0.001,epochs=3900):\n",
    "    np.random.seed(8675309)\n",
    "    bands = TrainData.shape[1]\n",
    "\n",
    "    #We want to use one hot encoded classes in order to adjust the weights of an artificial neural network by applying error.\n",
    "    OH_Encoded = np.zeros(shape=(TrainVal.shape[0],number_outputnodes)).astype(int)\n",
    "    for index in range(TrainVal.shape[0]):\n",
    "        OH_Encoded[index] = np.identity(number_outputnodes)[TrainVal[index].astype(int)].astype(int)\n",
    "\n",
    "    #Initialize layer weights and bias. Keep in mind we want to take random values upon a normalized Gaussian distribution for bias to aid stochastic gradient descent.\n",
    "    #Hidden layer: Relu\n",
    "    relu_weights, relu_bias = np.random.rand(bands,number_hiddennodes),np.random.randn(number_hiddennodes)\n",
    "\n",
    "    #Output layer: Softmax\n",
    "    softmax_weights,softmax_bias = np.random.rand(number_hiddennodes,number_outputnodes),np.random.randn(number_outputnodes)\n",
    "\n",
    "    #Remember that epochs is just the naming sense of how many times we train a model for artificial neural networks. You can just think of them as the same thing.\n",
    "\n",
    "    for iteration in range(epochs):\n",
    "        #Perform forward propagation\n",
    "        Weighted_bands = np.dot(TrainData,relu_weights)+relu_bias\n",
    "        Relu_layer = relu(Weighted_bands,0)\n",
    "        Softmax_layer = softmax(np.dot(Relu_layer,softmax_weights)+softmax_bias)\n",
    "\n",
    "        #Perform backpropagation\n",
    "        softmax_weight_error = np.dot(Relu_layer.transpose(),Softmax_layer-OH_Encoded)\n",
    "        softmax_bias_error = Softmax_layer-OH_Encoded\n",
    "        Relu_layer_derivative = relu(Weighted_bands,1)            #Remember the derivative is the slope in stochastic gradient descent.\n",
    "        relu_weight_error = np.dot(TrainData.transpose(),Relu_layer_derivative*np.dot(Softmax_layer-OH_Encoded,softmax_weights.transpose()))\n",
    "        relu_bias_error = np.dot(Softmax_layer-OH_Encoded,softmax_weights.transpose())*Relu_layer_derivative\n",
    "\n",
    "        #Adjust weights with error in relation to Training data. 0.001 is the standard learning rate for the layers of an artificial neural network.\n",
    "        relu_weights -= learningrate*relu_weight_error\n",
    "        softmax_weights -= learningrate*softmax_weight_error\n",
    "        relu_bias -= learningrate*relu_bias_error.sum(axis=0)\n",
    "        softmax_bias -= learningrate*softmax_bias_error.sum(axis=0)\n",
    "    return relu_weights,relu_bias,softmax_weights,softmax_bias\n",
    "\n",
    "#Accuracy. This takes the weights obtained through a Neural Network and uses them to classify a set of testing data.\n",
    "def accuracy(weights, TestData, TestVal, TrainData, TrainVal):\n",
    "    # Perform forward propagation For training set\n",
    "    Relu_layer_train = relu(np.dot(TrainData, weights[0]) + weights[1], 0)\n",
    "    Softmax_layer_train = softmax(np.dot(Relu_layer_train, weights[2]) + weights[3])\n",
    "    predictionTrain = np.argmax(Softmax_layer_train, axis=1)\n",
    "\n",
    "    # Perform forward propagation For test set\n",
    "    Relu_layer_test = relu(np.dot(TestData, weights[0]) + weights[1], 0)\n",
    "    Softmax_layer_test = softmax(np.dot(Relu_layer_test, weights[2]) + weights[3])\n",
    "    predictionTest = np.argmax(Softmax_layer_test, axis=1)\n",
    "    print('Training Accuracy: {:.3f}'.format(np.mean(predictionTrain == TrainVal)))\n",
    "    print('Validation Accuracy: {:.3f}'.format(np.mean(predictionTest == TestVal)))\n",
    "    return np.mean(predictionTest == TestVal)\n",
    "\n",
    "\n",
    "#Classification function. This takes the weights obtained through a Neural Network and uses them to classify a set of testing data.\n",
    "def classify(weights, TestData):\n",
    "    \n",
    "    #Perform forward propagation\n",
    "    Relu_layer = relu(np.dot(TestData,weights[0])+weights[1],0)\n",
    "    Softmax_layer = softmax(np.dot(Relu_layer,weights[2])+weights[3])\n",
    "    prediction = np.argmax(Softmax_layer,axis=1)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally train a neural network on our orthomosaic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.996\n",
      "Validation Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "TrainedNetwork = NeuralNetwork(TrainData,TrainVal,number_hiddennodes=6,number_outputnodes=5)\n",
    "prediction = accuracy(TrainedNetwork,TestData,TestVal, TrainData, TrainVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you want to try to find a better accuracy, the important hyperparameters are <b> number_hiddennodes, learningrate, epochs.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainedNetwork = NeuralNetwork(TrainData,TrainVal,number_hiddennodes=6,number_outputnodes=3, epochs = 10000)\n",
    "#prediction = classify(TrainedNetwork,TestData,TestVal, TrainData, TrainVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.9860\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=0)                    #Create and fit model\n",
    "forest.fit(TrainData, TrainVal)\n",
    "print(\"Accuracy on training set: {:.3f}\\nAccuracy on test set: {:.4f}\".format(forest.score(TrainData, TrainVal),forest.score(TestData, TestVal)))        #Display scores of classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the best random forest model's scores. Keep in mind that we're only using a one hidden layer ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To work with the PCA data change the file path to where the \n",
    "#TIFF and shape file is stored locally on your machine\n",
    "ortho_file = './ortho.tif'\n",
    "shp_file = './cropped.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We will take a cropped region and use our trained neural network to classify every pixel using forward propogation. The following code reads in a shape file which encompasses the desired region and then crops the orthomosaic. The pixels are then extracted and then the classify function is used to classify the pixels. The classified image is reshaped and written as a geotiff to be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "./ortho.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_shim.pyx\u001b[0m in \u001b[0;36mrasterio._shim.open_dataset\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ./ortho.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3fb53e43f19e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgeoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mout_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrop\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/neuralnetwork/lib/python3.8/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/neuralnetwork/lib/python3.8/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001b[0;32mrasterio/_base.pyx\u001b[0m in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: ./ortho.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "shp = gpd.read_file(shp_file)\n",
    "geoms = shp.geometry.values\n",
    "geoms = [mapping(geoms[0])]\n",
    "\n",
    "with rasterio.open(ortho_file) as src:\n",
    "    out_image, out_transform = mask(src,geoms,crop =True)\n",
    "    \n",
    "data = out_image[0]\n",
    "row, col = np.where(data != 0 )\n",
    "bands = out_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((row.size,bands))\n",
    "for ba in range(bands):\n",
    "    Y[:, ba] = np.extract(data != 0, out_image[ba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(Y.shape[1]):        \n",
    "    maxY = np.max(Y[:,x])\n",
    "    Y[:,x] = Y[:,x]/maxY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiedImage = classify(TrainedNetwork,Y)\n",
    "C_image = np.copy(out_image)[0]\n",
    "C_image[row,col] = classifiedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data set and write it\n",
    "new_dataset = rasterio.open(\n",
    "    './classified.tif',\n",
    "    'w',\n",
    "    driver = 'GTiff',\n",
    "    height = C_image.shape[0],\n",
    "    width = C_image.shape[1],\n",
    "    count = 1,\n",
    "    crs = src.crs,\n",
    "    dtype = src.dtypes[0],\n",
    "    transform = out_transform,\n",
    "    nodata = 8,\n",
    "    )\n",
    "# write the new file\n",
    "new_dataset.write(C_image,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetwork",
   "language": "python",
   "name": "neuralnetwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
